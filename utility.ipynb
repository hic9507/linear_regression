{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e1cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from IPython.display import display_html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67764cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/kimtaehun/breif-eda-and-xgb-baseline-with-full-dataset\n",
    "def summary(df):\n",
    "    print(f'data shape: {df.shape}')\n",
    "    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "    summ['#missing'] = df.isnull().sum().values \n",
    "    summ['%missing'] = df.isnull().sum().values / len(df) * 100\n",
    "    summ['#unique'] = df.nunique().values\n",
    "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "\n",
    "    # Debug: print the columns of desc\n",
    "    # print(\"Columns in desc:\", desc.columns)\n",
    "    \n",
    "    if 'min' in desc.columns:\n",
    "        summ['min'] = desc['min'].values\n",
    "    else:\n",
    "        summ['min'] = 'N/A'\n",
    "\n",
    "    if 'max' in desc.columns:\n",
    "        summ['max'] = desc['max'].values\n",
    "    else:\n",
    "        summ['max'] = 'N/A'\n",
    "    \n",
    "    summ['first value'] = df.iloc[0].values if len(df) > 0 else 'N/A'\n",
    "    summ['second value'] = df.iloc[1].values if len(df) > 1 else 'N/A'\n",
    "    summ['third value'] = df.iloc[2].values if len(df) > 2 else 'N/A'    \n",
    "\n",
    "#    return summ\n",
    "    display_html(summ)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6dc0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From chatGPT and then me editng it\n",
    "def ohe_categorical(df, categorical_cols, threshold=10, keep_col = True):\n",
    "    \"\"\"\n",
    "    One-hot encodes the categorical columns in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        categorical_cols (list): List of column names to one-hot encode.\n",
    "        threshold (int): The threshold for the number of unique values\n",
    "                         in a column to decide whether to one-hot encode it.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with one-hot encoded columns.\n",
    "        list: List of columns that weren't one-hot encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find the columns that weren't one-hot encoded\n",
    "    not_encoded_cols = []\n",
    "\n",
    "    # Iterate through the categorical columns\n",
    "    for col in categorical_cols:\n",
    "        unique_count = df[col].nunique()\n",
    "        if unique_count <= threshold:\n",
    "            # Perform one-hot encoding for columns with unique_count less than or equal to the threshold\n",
    "            if keep_col: copied_col = df[col]\n",
    "            df = pd.get_dummies(df, columns=[col])\n",
    "            if keep_col: df[col] = copied_col\n",
    "            \n",
    "        else:\n",
    "            # Append the column name to the not_encoded_cols list\n",
    "            not_encoded_cols.append(col)\n",
    "\n",
    "    return df, not_encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edd1e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_by_type(df, data_type):\n",
    "    columns_list = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == data_type:\n",
    "            columns_list.append(column)\n",
    "    \n",
    "    return columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb3216ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/andradaolteanu/rsna-fracture-detection-dicom-images-explore\n",
    "def df_info(df, name=\"Default\"): \n",
    "    print(clr.S+f\"=== {name} ===\"+clr.E)\n",
    "#    print(clr.S+f\"Shape:\"+clr.E, df.shape)\n",
    "    print(clr.S+f\"Shape:\"+clr.E, format(df.shape[0], \",\"), format(df.shape[1], \",\"))\n",
    "    print(clr.S+f\"Missing Values:\"+clr.E, format(df.isna().sum().sum(), \",\"), \"total missing datapoints.\")\n",
    "    print(clr.S+\"Columns:\"+clr.E, list(df.columns), \"\\n\")\n",
    "    \n",
    "    display_html(df.tail())\n",
    "    print(\"\\n\")\n",
    "\n",
    "class clr:\n",
    "    S = '\\033[1m' + '\\033[94m'\n",
    "    E = '\\033[0m'\n",
    "    \n",
    "my_colors = [\"#5EAFD9\", \"#449DD1\", \"#3977BB\", \n",
    "             \"#2D51A5\", \"#5C4C8F\", \"#8B4679\",\n",
    "             \"#C53D4C\", \"#E23836\", \"#FF4633\", \"#FF5746\"]\n",
    "CMAP1 = ListedColormap(my_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41506f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These helper and data cleaning functions are from the old fast.ai course\n",
    "# The repository is here: https://github.com/fastai/fastai/tree/master/old\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)\n",
    "        \n",
    "def make_date(df, date_field:str):\n",
    "    \"Make sure `df[field_name]` is of the right date type.\"\n",
    "    field_dtype = df[date_field].dtype\n",
    "    if isinstance(field_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        field_dtype = np.datetime64\n",
    "    if not np.issubdtype(field_dtype, np.datetime64):\n",
    "        df[date_field] = pd.to_datetime(df[date_field], infer_datetime_format=True)\n",
    "        \n",
    "\n",
    "\n",
    "def add_datepart(df, fldnames, drop=True, time=False, errors=\"raise\"):\n",
    "    \"\"\"\n",
    "    Add Date Parts converts a column of df from a datetime64 to many columns containing \n",
    "    the information from the date. It returns a modified version of the original DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(fldnames, str):\n",
    "        fldnames = [fldnames]\n",
    "    \n",
    "    for fldname in fldnames:\n",
    "        fld = df[fldname]\n",
    "        fld_dtype = fld.dtype\n",
    "        \n",
    "        if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "            fld_dtype = np.datetime64\n",
    "\n",
    "        if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "            df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True, errors=errors)\n",
    "        \n",
    "        targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "        attr = ['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "                'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', \n",
    "                'Is_year_end', 'Is_year_start']\n",
    "        \n",
    "        if time:\n",
    "            attr = attr + ['Hour', 'Minute', 'Second']\n",
    "        \n",
    "        for n in attr:\n",
    "            df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "        \n",
    "        if drop:\n",
    "            df = df.drop(fldname, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "        \n",
    "        \n",
    "def ifnone (a,b): #(a:Any,b:Any)->Any:\n",
    "    \"`a` if `a` is not None, otherwise `b`.\"\n",
    "    return b if a is None else a\n",
    "\n",
    "def train_cats(df):    \n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "\n",
    "def apply_cats(df, trn):\n",
    "    for n,c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = c.astype('category').cat.as_ordered()\n",
    "            df[n].cat.set_categories(trn[n].cat.categories, ordered=True, inplace=True)\n",
    "\n",
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n",
    "        df[name] = pd.Categorical(col).codes+1\n",
    "\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)      \n",
    "\n",
    "############################\n",
    "# End fast.ai funcitons...\n",
    "############################\n",
    "\n",
    "# This function I believe came from this guy: https://www.kaggle.com/siavrez\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c38906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
